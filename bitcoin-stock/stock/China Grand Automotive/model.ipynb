{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "\n",
    "# keras lib\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/600297.SS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_model:\n",
    "    \n",
    "    def __init__(self, stock: stock_data, model=None, scaler=None, tar_pos=None):\n",
    "        \n",
    "        # initial variables\n",
    "        self.stock = stock\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.tar_pos = tar_pos\n",
    "        self.lstm_inputs = list(stock.data.columns)\n",
    "        \n",
    "        \n",
    "        if not model:\n",
    "            print('Model not created')\n",
    "        if not scaler:\n",
    "            print('lstm dataset not created')\n",
    "        print('Data read: ')\n",
    "        print(self.stock.data.info())\n",
    "        print('please create lstm dataset using create_lstm_data()')\n",
    "       \n",
    "    def create_features_data(self, seq, fs, ns, windows, ts=0.1):\n",
    "        self.seq= seq\n",
    "        self.fs = fs\n",
    "        self.trn_len = int(len(self.stock.data)*(1-ts))\n",
    "        self.skip = max(max(ns), max(windows))\n",
    "        \n",
    "        self.stock.preprocess(ns=[1,5], windows=[1,5])\n",
    "        cols = [col for col in self.stock.proc_data.columns if col not in self.stock.data.columns]\n",
    "        not_return_cols = [col for col in self.stock.proc_data.columns if not 'return' not in col]\n",
    "        self.n_features = len(cols)\n",
    "        proc_data = pd.DataFrame()\n",
    "        proc_data[cols] = self.stock.proc_data[cols][self.skip:]\n",
    "        scaler = MinMaxScaler()\n",
    "        proc_data[not_return_cols] = scaler.fit_transform(proc_data[not_return_cols])\n",
    "        x = []\n",
    "        for i in range(seq, len(proc_data)-fs):\n",
    "            x.append(proc_data[i-seq:i][cols].values)\n",
    "        x = np.array(x).reshape(-1, seq, self.n_features)\n",
    "        self.features_xtrain, self.features_xtest = x[:self.trn_len], x[self.trn_len:]\n",
    "        \n",
    "        \n",
    "    def create_lstm_data(self, tar):\n",
    "        \n",
    "        if not self.scaler:\n",
    "            print('creating new lstm dataset')\n",
    "        df = self.stock.data[self.lstm_inputs].copy()\n",
    "        scaler = MinMaxScaler()\n",
    "        df[self.lstm_inputs] = scaler.fit_transform(df[self.lstm_inputs])\n",
    "        x,y = [], []\n",
    "        for i in range(self.seq+self.skip, len(df)-self.fs):\n",
    "            x.append(df[i-self.seq:i][self.lstm_inputs].values)\n",
    "            y.append(df[i:i+self.fs][tar].values)\n",
    "        \n",
    "        # assigning class vars\n",
    "        self.x = np.array(x).reshape(-1, self.seq, len(self.lstm_inputs))\n",
    "        self.y = np.array(y).reshape(-1, self.fs)\n",
    "        self.scaler = scaler\n",
    "        self.tar_pos = self.lstm_inputs.index(tar)\n",
    "        \n",
    "        trn_len = self.trn_len\n",
    "        self.xtrain, self.xtest = self.x[:trn_len], self.x[trn_len:]\n",
    "        self.ytrain, self.ytest = self.y[:trn_len], self.y[trn_len:]\n",
    "        \n",
    "    def multi_input_model(self):\n",
    "        feature_inputs = Input(shape=(self.seq, self.n_features,), name='feat_inp')\n",
    "        x = LSTM(2*self.n_features, return_sequences=True)(feature_inputs)\n",
    "        x = LSTM(10)(x)\n",
    "        feature_outputs = Dense(30, activation='linear')(x)\n",
    "        \n",
    "        lstm_inputs = Input(shape=(self.seq, len(self.lstm_inputs)), name='lstm_inp')\n",
    "        x = LSTM(32, return_sequences=True)(lstm_inputs)\n",
    "        x = LSTM(16)(x)\n",
    "        lstm_outputs = Dense(30)(x)\n",
    "        \n",
    "        join = concatenate([feature_outputs, lstm_outputs])\n",
    "        final_output = Dense(self.fs, activation='linear')(join)\n",
    "        model = Model(inputs=[feature_inputs, lstm_inputs], outputs=[final_output])\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        self.model = model\n",
    "        print(model.summary())\n",
    "     \n",
    "    def train_multi_input(self, bs=1, epochs=100):\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \\\n",
    "                                          patience=3, min_lr=0.0000001, verbose=1)\n",
    "        self.model.fit([self.features_xtrain, self.xtrain], [self.ytrain], validation_split=0.2, \\\n",
    "                      batch_size=bs, epochs=epochs, callbacks=[es, reduce_lr], shuffle=False)\n",
    "        \n",
    "    def train(self, bs=1, epochs=100):\n",
    "        if not self.model: \n",
    "            print('Model has not been built')\n",
    "        else:\n",
    "            es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            es2 = EarlyStopping(monitor='loss', patience=10)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \\\n",
    "                                          patience=3, min_lr=0.0000001, verbose=1)\n",
    "            self.model.fit(self.data_xtrain, self.data_ytrain, epochs=epochs, batch_size=bs, \\\n",
    "                           validation_split=0.1, shuffle=True, callbacks=[es, reduce_lr])\n",
    "    \n",
    "    def predict(self, x, inverse=False):\n",
    "        preds = self.model.predict(x)\n",
    "        return self.inverse(preds) if inverse else preds\n",
    "        \n",
    "        \n",
    "    def trend_accuracy(self, x, y):\n",
    "        preds = self.get_trends(self.predict(x, inverse=True))\n",
    "        actuals = self.get_trends(self.inverse(y))\n",
    "        return sum(1 for a,b in zip(preds, actuals) if a==b) / len(preds)\n",
    "    \n",
    "    # helpers\n",
    "    \n",
    "    def inverse(self, vals):\n",
    "        dmin, dmax = self.scaler.data_min_[self.tar_pos], self.scaler.data_max_[self.tar_pos]\n",
    "        low, high = self.scaler.feature_range\n",
    "        inv = np.vectorize(lambda x: (x-low)/(high-low)*(dmax-dmin)+dmin)\n",
    "        return np.round(inv(vals),4)\n",
    "    \n",
    "    def get_trends(self, x):\n",
    "        x = x.squeeze()\n",
    "        return [(1 if x[i+1]-x[i]>0 else -1) for i in range(len(x)-1)]\n",
    "    \n",
    "    def comparison_plot(self, predictions, real):\n",
    "        plt.figure(figsize=(18,8))\n",
    "        plt.plot(predictions, label='predictions')\n",
    "        plt.plot(real, label='real')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/600297.SS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = df.query(\"timestamp>'2016-08-01'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>7.0231</td>\n",
       "      <td>7.0538</td>\n",
       "      <td>6.9231</td>\n",
       "      <td>7.0461</td>\n",
       "      <td>31849307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2016-08-05</td>\n",
       "      <td>7.1539</td>\n",
       "      <td>7.2385</td>\n",
       "      <td>7.0538</td>\n",
       "      <td>7.0615</td>\n",
       "      <td>38740006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>7.1769</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>7.0615</td>\n",
       "      <td>7.1769</td>\n",
       "      <td>27544422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>7.2308</td>\n",
       "      <td>7.2769</td>\n",
       "      <td>7.1385</td>\n",
       "      <td>7.1692</td>\n",
       "      <td>33128103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2016-08-02</td>\n",
       "      <td>7.1077</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>7.0538</td>\n",
       "      <td>7.2615</td>\n",
       "      <td>39938440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp    open    high     low   close    volume\n",
       "674  2016-08-08  7.0231  7.0538  6.9231  7.0461  31849307\n",
       "675  2016-08-05  7.1539  7.2385  7.0538  7.0615  38740006\n",
       "676  2016-08-04  7.1769  7.2000  7.0615  7.1769  27544422\n",
       "677  2016-08-03  7.2308  7.2769  7.1385  7.1692  33128103\n",
       "678  2016-08-02  7.1077  7.3000  7.0538  7.2615  39938440"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = stock_data(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not created\n",
      "lstm dataset not created\n",
      "Data read: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 679 entries, 2019-05-22 to 2016-08-02\n",
      "Data columns (total 5 columns):\n",
      "open      679 non-null float64\n",
      "high      679 non-null float64\n",
      "low       679 non-null float64\n",
      "close     679 non-null float64\n",
      "volume    679 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 31.8+ KB\n",
      "None\n",
      "please create lstm dataset using create_lstm_data()\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.create_features_data(10, 1, [1,5], [1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new lstm dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "lstm.create_lstm_data('close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(lstm.features_xtrain).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "feat_inp (InputLayer)           (None, 10, 30)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_inp (InputLayer)           (None, 10, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 10, 60)       21840       feat_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 10, 32)       4864        lstm_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 10)           2840        lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_37 (LSTM)                  (None, 16)           3136        lstm_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 30)           330         lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 30)           510         lstm_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 60)           0           dense_44[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 1)            61          concatenate_12[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 33,581\n",
      "Trainable params: 33,581\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm.multi_input_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 488 samples, validate on 123 samples\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 28s 58ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks.py:543: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "  3/488 [..............................] - ETA: 22s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks.py:1090: RuntimeWarning: invalid value encountered in less\n",
      "  self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370/488 [=====================>........] - ETA: 5s - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-8ff64f052014>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_multi_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-196-c31d78dc43f9>\u001b[0m in \u001b[0;36mtrain_multi_input\u001b[1;34m(self, bs, epochs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                                           patience=3, min_lr=0.0000001, verbose=1)\n\u001b[0;32m     86\u001b[0m         self.model.fit([self.features_xtrain, self.xtrain], [self.ytrain], validation_split=0.2, \\\n\u001b[1;32m---> 87\u001b[1;33m                       batch_size=bs, epochs=epochs, callbacks=[es, reduce_lr], shuffle=False)\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm.train_multi_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36 keras",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
