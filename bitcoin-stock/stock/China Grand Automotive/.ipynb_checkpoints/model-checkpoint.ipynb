{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "\n",
    "# keras lib\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Input, concatenate\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/600297.SS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_model:\n",
    "    \n",
    "    def __init__(self, stock: stock_data, model=None, scaler=None, tar_pos=None):\n",
    "        \n",
    "        # initial variables\n",
    "        self.stock = stock\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.tar_pos = tar_pos\n",
    "        self.lstm_inputs = list(stock.data.columns)\n",
    "        \n",
    "        \n",
    "        if not model:\n",
    "            print('Model not created')\n",
    "        if not scaler:\n",
    "            print('lstm dataset not created')\n",
    "        print('Data read: ')\n",
    "        print(self.stock.data.info())\n",
    "        print('please create lstm dataset using create_lstm_data()')\n",
    "       \n",
    "    def create_features_data(self, seq, fs, ns, windows, ts=0.1):\n",
    "        self.seq= seq\n",
    "        self.fs = fs\n",
    "        self.trn_len = int(len(self.stock.data)*(1-ts))\n",
    "        self.skip = max(max(ns), max(windows))\n",
    "        \n",
    "        self.stock.preprocess(ns=[1,5], windows=[1,5])\n",
    "        cols = [col for col in self.stock.proc_data.columns if col not in self.stock.data.columns]\n",
    "        self.n_features = len(cols)\n",
    "        proc_data = pd.DataFrame()\n",
    "        proc_data[cols] = self.stock.proc_data[cols][self.skip:]\n",
    "        x = []\n",
    "        for i in range(seq, len(proc_data)-fs):\n",
    "            x.append(proc_data[i-seq:i][cols].values)\n",
    "        x = np.array(x).reshape(-1, seq, self.n_features)\n",
    "        self.features_xtrain, self.features_xtest = x[:self.trn_len], x[self.trn_len:]\n",
    "        \n",
    "        \n",
    "    def create_lstm_data(self, tar):\n",
    "        \n",
    "        if not self.scaler:\n",
    "            print('creating new lstm dataset')\n",
    "        df = self.stock.data[self.lstm_inputs].copy()\n",
    "        scaler = MinMaxScaler()\n",
    "        df[self.lstm_inputs] = scaler.fit_transform(df[self.lstm_inputs])\n",
    "        x,y = [], []\n",
    "        for i in range(self.seq+self.skip, len(df)-self.fs):\n",
    "            x.append(df[i-self.seq:i][self.lstm_inputs].values)\n",
    "            y.append(df[i:i+self.fs][tar].values)\n",
    "        \n",
    "        # assigning class vars\n",
    "        self.x = np.array(x).reshape(-1, self.seq, len(self.lstm_inputs))\n",
    "        self.y = np.array(y).reshape(-1, self.fs)\n",
    "        self.scaler = scaler\n",
    "        self.tar_pos = self.lstm_inputs.index(tar)\n",
    "        \n",
    "        trn_len = self.trn_len\n",
    "        self.xtrain, self.xtest = self.x[:trn_len], self.x[trn_len:]\n",
    "        self.ytrain, self.ytest = self.y[:trn_len], self.y[trn_len:]\n",
    "        \n",
    "    def multi_input_model(self):\n",
    "        feature_inputs = Input(shape=(self.seq, self.n_features,), name='feat_inp')\n",
    "        x = LSTM(2*self.n_features, return_sequences=True)(feature_inputs)\n",
    "        x = LSTM(10)(x)\n",
    "        feature_outputs = Dense(30, activation='linear')(x)\n",
    "        \n",
    "        lstm_inputs = Input(shape=(self.seq, len(self.lstm_inputs)), name='lstm_inp')\n",
    "        x = LSTM(32, return_sequences=True)(lstm_inputs)\n",
    "        x = LSTM(16)(x)\n",
    "        lstm_outputs = Dense(30)(x)\n",
    "        \n",
    "        join = concatenate([feature_outputs, lstm_outputs])\n",
    "        final_output = Dense(self.fs, activation='linear')(join)\n",
    "        model = Model(inputs=[feature_inputs, lstm_inputs], outputs=[final_output])\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        self.model = model\n",
    "        print(model.summary())\n",
    "     \n",
    "    def train_multi_input(self, bs=1, epochs=100):\n",
    "        es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \\\n",
    "                                          patience=3, min_lr=0.0000001, verbose=1)\n",
    "        self.model.fit([self.features_xtrain, self.xtrain], [self.ytrain], validation_split=0.2, \\\n",
    "                      batch_size=bs, epochs=epochs, callbacks=[es, reduce_lr], shuffle=False)\n",
    "        \n",
    "    def train(self, bs=1, epochs=100):\n",
    "        if not self.model: \n",
    "            print('Model has not been built')\n",
    "        else:\n",
    "            es = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            es2 = EarlyStopping(monitor='loss', patience=10)\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, \\\n",
    "                                          patience=3, min_lr=0.0000001, verbose=1)\n",
    "            self.model.fit(self.data_xtrain, self.data_ytrain, epochs=epochs, batch_size=bs, \\\n",
    "                           validation_split=0.1, shuffle=True, callbacks=[es, reduce_lr])\n",
    "    \n",
    "    def predict(self, x, inverse=False):\n",
    "        preds = self.model.predict(x)\n",
    "        return self.inverse(preds) if inverse else preds\n",
    "        \n",
    "        \n",
    "    def trend_accuracy(self, x, y):\n",
    "        preds = self.get_trends(self.predict(x, inverse=True))\n",
    "        actuals = self.get_trends(self.inverse(y))\n",
    "        return sum(1 for a,b in zip(preds, actuals) if a==b) / len(preds)\n",
    "    \n",
    "    # helpers\n",
    "    \n",
    "    def inverse(self, vals):\n",
    "        dmin, dmax = self.scaler.data_min_[self.tar_pos], self.scaler.data_max_[self.tar_pos]\n",
    "        low, high = self.scaler.feature_range\n",
    "        inv = np.vectorize(lambda x: (x-low)/(high-low)*(dmax-dmin)+dmin)\n",
    "        return np.round(inv(vals),4)\n",
    "    \n",
    "    def get_trends(self, x):\n",
    "        x = x.squeeze()\n",
    "        return [(1 if x[i+1]-x[i]>0 else -1) for i in range(len(x)-1)]\n",
    "    \n",
    "    def comparison_plot(self, predictions, real):\n",
    "        plt.figure(figsize=(18,8))\n",
    "        plt.plot(predictions, label='predictions')\n",
    "        plt.plot(real, label='real')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/600297.SS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = df.query(\"timestamp>'2016-08-01'\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>7.0231</td>\n",
       "      <td>7.0538</td>\n",
       "      <td>6.9231</td>\n",
       "      <td>7.0461</td>\n",
       "      <td>31849307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2016-08-05</td>\n",
       "      <td>7.1539</td>\n",
       "      <td>7.2385</td>\n",
       "      <td>7.0538</td>\n",
       "      <td>7.0615</td>\n",
       "      <td>38740006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>7.1769</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>7.0615</td>\n",
       "      <td>7.1769</td>\n",
       "      <td>27544422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2016-08-03</td>\n",
       "      <td>7.2308</td>\n",
       "      <td>7.2769</td>\n",
       "      <td>7.1385</td>\n",
       "      <td>7.1692</td>\n",
       "      <td>33128103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>2016-08-02</td>\n",
       "      <td>7.1077</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>7.0538</td>\n",
       "      <td>7.2615</td>\n",
       "      <td>39938440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp    open    high     low   close    volume\n",
       "674  2016-08-08  7.0231  7.0538  6.9231  7.0461  31849307\n",
       "675  2016-08-05  7.1539  7.2385  7.0538  7.0615  38740006\n",
       "676  2016-08-04  7.1769  7.2000  7.0615  7.1769  27544422\n",
       "677  2016-08-03  7.2308  7.2769  7.1385  7.1692  33128103\n",
       "678  2016-08-02  7.1077  7.3000  7.0538  7.2615  39938440"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = stock_data(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not created\n",
      "lstm dataset not created\n",
      "Data read: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 679 entries, 2019-05-22 to 2016-08-02\n",
      "Data columns (total 5 columns):\n",
      "open      679 non-null float64\n",
      "high      679 non-null float64\n",
      "low       679 non-null float64\n",
      "close     679 non-null float64\n",
      "volume    679 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 31.8+ KB\n",
      "None\n",
      "please create lstm dataset using create_lstm_data()\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:364: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:365: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "lstm.create_features_data(10, 1, [1,5], [1,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new lstm dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "lstm.create_lstm_data('close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "feat_inp (InputLayer)           (None, 10, 30)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_inp (InputLayer)           (None, 10, 5)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_30 (LSTM)                  (None, 10, 60)       21840       feat_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 10, 32)       4864        lstm_inp[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 10)           2840        lstm_30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  (None, 16)           3136        lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 30)           330         lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 30)           510         lstm_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 60)           0           dense_41[0][0]                   \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1)            61          concatenate_11[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 33,581\n",
      "Trainable params: 33,581\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm.multi_input_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 488 samples, validate on 123 samples\n",
      "Epoch 1/100\n",
      "488/488 [==============================] - 26s 53ms/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks.py:543: RuntimeWarning: invalid value encountered in less\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "  3/488 [..............................] - ETA: 19s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\Anaconda3\\envs\\py36\\lib\\site-packages\\keras\\callbacks.py:1090: RuntimeWarning: invalid value encountered in less\n",
      "  self.monitor_op = lambda a, b: np.less(a, b - self.min_delta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 23s 47ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      " 52/488 [==>...........................] - ETA: 18s - loss: nan"
     ]
    }
   ],
   "source": [
    "lstm.train_multi_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36 keras",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
